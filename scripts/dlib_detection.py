#!/usr/bin/env python
# -*- encoding: utf-8 -*-
'''
version 1
@time       :2021/12/11 10:27:35
@author     :Mingdong
'''
'''
version 2
add marker and text publisher to mark the detected face in map generated by SLAM
@time       :2021/12/12 22:05:10
@author     :Ge Sun
'''

import os
# Import ROS libraries and messages
import rospy
from sensor_msgs.msg import Image, LaserScan
from geometry_msgs.msg import Quaternion

# Import OpenCV libraries and tools
import cv2
from cv_bridge import CvBridge, CvBridgeError
import numpy as np
import face_recognition

import rospkg
import math
from visualization_msgs.msg import Marker
# https://github.com/ageitgey/face_recognition

# Define a function to show the image in an OpenCV Window
def show_image(img):
    cv2.imshow('Image Window', img)
    cv2.waitKey(1)

# Define a callback for the Image message
def image_callback(img_msg):
    # log some info about the image topic
    # rospy.loginfo(img_msg.header)

    # Try to convert the ROS Image message to a CV2 Image
    try:
        cv_image = bridge.imgmsg_to_cv2(img_msg, 'passthrough')
    except:
        rospy.logerr("CvBridge Error: {0}".format("unknown error"))

    # Flip the image 90deg
    # cv_image = cv2.transpose(cv_image)
    cv_image = cv2.flip(cv_image,1)
    # scale down the image
    cv_image = cv2.resize(cv_image, (0,0), fx=scale, fy=scale)

    # Detection using dlib and face_recognition
    # add some lag,锁帧hhh
    if img_msg.header.seq%2==0:
        det_img = face_detection_match(cv_image)
        #  image color
        det_img = cv2.cvtColor(det_img, cv2.COLOR_BGR2RGB)
        # Show the detected image
        show_image(det_img)



def face_match(input_img,face_location):
    # 把已经检测的位置输入，计算快一些
    image_to_be_matched_encoded = face_recognition.face_encodings(input_img,known_face_locations=face_location)[0]
    Id = 0
    for i in range(len(images)):
        result = face_recognition.compare_faces([image_to_be_matched_encoded], images_encodings[i])
        if result[0] == True:
            Id = int(images[i].split('.')[0][-1])

    return Id


# face detection
def face_detection_match(img):
    face_locations = face_recognition.face_locations(img)
    show_img = img
    if len(face_locations)>0:
        for face_location in  [face_locations[0]]:
            show_img = cv2.putText(show_img, 'face detected', (img.shape[0]-150,10), font, 0.5, (255, 0, 0), 2)
            top, right, bottom, left = face_location
            # face_image = img[top:bottom, left:right]
            cv2.rectangle(show_img, (left, top), (right, bottom), (255, 0, 0), 2)
            
            Id = face_match(img,face_locations)       
            img = cv2.putText(show_img, "%s"%labels[Id], (left,top-5), font, 0.5, (255, 0, 0), 2)

            # compute the position of ROI_center in inputted image
            ROI_center = [(left + right) / 2, (top + bottom) / 2]
            # when ROI_center is between 1/4 and 3/4 range of image length, publish marker
            if ((ROI_center[0] > (128 * scale )) & (ROI_center[0] < (384 * scale))):
                marker_make(ROI_center[0], ROI_center[1], labels[Id])
    else:
        show_img = cv2.putText(img, 'no face detected', (img.shape[0]-150,10), font, 0.5, (255, 0, 0), 2)
        marker_clear()
    return show_img


def laser_callback(laser_msg):
    global depth_ROI_center, theta_x
    data = laser_msg
    angle_increment = data.angle_increment
    ranges = data.ranges
    depth_ROI_center = ranges[int((theta_x+math.pi*5/9)/angle_increment)]


def marker_make(x, y, face_name):
    global depth_ROI_center, theta_x
    # relative angle of ROI_center to the center line of camera
    # the computation methode is:
    # theta_x = np.arctan((x / (0.5 * 512 * scale) - 1) * np.tan(0.5 * math.pi / 4))
    # theta_y = np.arctan((x / (0.5 * 512 * scale) - 1) * np.tan(0.5 * math.pi / 4))
    # np.tan(0.5 * math.pi / 4) = 0.41421
    theta_x = np.arctan((x / (256 * scale) - 1) * 0.41421)
    theta_y = np.arctan((y / (256 * scale) - 1) * 0.41421)

    # coordinate of ROI_center in base_link frame
    ROI_center_x = - depth_ROI_center * np.sin(theta_x)
    ROI_center_z = 0.55
    ROI_center_y = - np.sqrt((depth_ROI_center * np.cos(theta_y)) ** 2 - ROI_center_x ** 2)

    pubMarker([ROI_center_x, ROI_center_y, ROI_center_z], face_name)


def pubMarker(p, tx):

    arrow = Marker()
    arrow.header.frame_id = "/base_link"
    arrow.header.stamp = rospy.Time(0)
    arrow.id = 0
    arrow.ns = 'marker'
    arrow.type = Marker.CUBE
    arrow.action = Marker.ADD
    arrow.pose.position.x = p[0]
    arrow.pose.position.y = p[1]
    arrow.pose.position.z = p[2]
    arrow.color.a = 1.0  # Don't forget to set the alpha!
    arrow.color.r = 0
    arrow.color.g = 1
    arrow.color.b = 0
    arrow.pose.orientation.x = 0
    arrow.pose.orientation.y = 0
    arrow.pose.orientation.z = 0
    arrow.pose.orientation.w = 1
    arrow.scale.x = 0.3
    arrow.scale.y = 0.3
    arrow.scale.z = 0.3

    text = Marker()
    text.header.frame_id = "/base_link"
    text.header.stamp = rospy.Time(0)
    text.id = 1
    text.ns = 'text'
    text.type = Marker.TEXT_VIEW_FACING
    text.action = Marker.ADD
    text.pose.position.x = p[0]
    text.pose.position.y = p[1]
    text.pose.position.z = p[2] + 0.5
    text.color.a = 1.0
    text.color.r = 1
    text.color.g = 0
    text.color.b = 0
    text.text = tx
    text.scale.x = 10.0
    text.scale.y = 10.0
    text.scale.z = 1.0
    # rospy.loginfo('publishing marker')
    pub_marker.publish(arrow)
    pub_text.publish(text)


def marker_clear():
    clr = Marker()
    clr.id = 0
    clr.color.a = 0.0
    clr.action = Marker.DELETEALL
    pub_marker.publish(clr)
    pub_text.publish(clr)
    # rospy.loginfo('refreshing marker')


if __name__ =='__main__':
    # scale is used to scale the image for faster computation
    # theta_x is the relative angle of ROI to the center of the image in x direction (length)
    # depth_ROI_center is the depth of ROI_center gotten by laser
    global scale, theta_x, depth_ROI_center
    scale = 0.5
    theta_x = 0.0
    depth_ROI_center = 0.0
    labels = ['unknown','Obama', 'Avril', 'Zhang', 'Legolas', 'Levi']
    font = cv2.FONT_HERSHEY_SIMPLEX
    # F5 debug
    # img_templete_dir = './src/detection/images_match'

    # 正式使用
    rospack = rospkg.RosPack()
    pkg_path = rospack.get_path('roas6000_final')
    img_path = pkg_path + '/images_match'
    img_templete_dir = os.path.join(os.getcwd(), img_path)
    # img_templete_dir = os.path.join(os.getcwd(), '/images_match')
    images = os.listdir(img_templete_dir)

    images_encodings = []
    for d in images:
        current_image = face_recognition.load_image_file(os.path.join(img_templete_dir,d))
        current_image_encoded = face_recognition.face_encodings(current_image)[0]
        images_encodings.append(current_image_encoded)
    
    # Initialize the ROS Node named 'camera_opencv', allow multiple nodes to be run with this name
    rospy.init_node('camera_opencv', anonymous=True)
    # Print "Hello ROS!" to the Terminal and to a ROS Log file located in ~/.ros/log/loghash/*.log
    # rospy.loginfo('Hello ROS!')

    # Initialize the CvBridge class
    bridge = CvBridge()
    # Initalize a subscriber to the "/vrep/image" topic with the function "image_callback" as a callback
    sub_image = rospy.Subscriber('/vrep/image', Image, image_callback)

    ROI_center_list = []
    pub_marker = rospy.Publisher('visualization_marker', Marker, queue_size=0)
    pub_text = rospy.Publisher('visualization_text', Marker, queue_size=0)

    sub_laser = rospy.Subscriber('/vrep/scan', LaserScan, laser_callback)
    # Initialize an OpenCV Window named "Image Window"
    cv2.namedWindow('Image Window', 1)

    # Loop to keep the program from shutting down unless ROS is shut down, or CTRL+C is pressed
    while not rospy.is_shutdown():
        rospy.spin()